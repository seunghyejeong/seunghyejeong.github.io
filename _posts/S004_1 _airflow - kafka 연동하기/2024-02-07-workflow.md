---
title: workflow, Day 5
author: bami jeong
categories:
  - Kafka
  - Airflow
tags:
  - Airflow
  - Kafka
  - Workflow
  - Data Pipeline
---

---
## Project Name: 
#### Date: 2024-02-07 09:13 
#### Tag:
---
# Contents:

- [b] REF
> [python docs](https://pypi.org/project/airflow-provider-kafka/)

- [*] ì§± ì¢‹ì€ REF  
> [airflowì˜ ëª¨ë“  provider,modules](https://registry.astronomer.io/providers/apache-airflow-providers-apache-kafka/versions/1.3.1)![[Pasted image 20240207094048.png]]![[Pasted image 20240207094117.png]]
> [useage](https://www.youtube.com/watch?v=UzGQ8R4F6z4)



## python library for airflow 

#airflowpip #airflowlibrary

#### ë¬¸ì œ
> airflow ui > connectionì— ìˆëŠ” `conn type`ì— `apache kafka`ê°€ ì—†ìŒ.

- ìœ„ì˜ ë§í¬ì—ì„œ ì°¾ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¶”ê°€í•´ì¤Œ 

```bassh
pip install airflow-provider-kafka
pip install apache-airflow-providers-apache-kafka==1.3.1
pip install confluent-kafka
```

#### í•´ê²°ì“°
- ë“œë£¨ì™€

![[Pasted image 20240207105155.png]]
#### error 

bash: 
```python 
airflow webserver -p 8080
```

get error:
```bash
TypeError: SqlAlchemySessionInterface.__init__() missing 4 required positional arguments: 'sequence', 'schema', 'bind_key', and 'sid_length'

```
![[Pasted image 20240207095631.png]]

solve:
```python
pip install Flask-Session==0.5.0 
```

## network check

- [b] REF from GTP
#networkcheck #nc_vz #telnet
```markdown
**Test Communication**: 
Once you have the IP addresses, you can test communication between the containers. You can use tools like `curl` or `telnet` to test connectivity over specific ports.

For example, on vm1, you can run:
`curl <vm2_container_ip>:<port>`

And on vm2, you can run:
`curl <vm1_container_ip>:<port>`

Replace `<vm2_container_ip>` and `<port>` with the IP address and port of the container in vm2, and `<vm1_container_ip>` and `<port>` with the IP address and port of the container in vm1.

**Netcat Test**:

- Install netcat (`nc`) on both vm1 and vm2 if not already installed.
- From vm2, run `nc -zv <vm1_public_ip> <container1_port>`.
- If you see a successful connection message, it confirms that the communication is established.
- ```

### 1. vm1 ğŸ”— vm2
```bash
$ telnet {VM1orVM2_MASTER_IP} 22
```

- airflow vmì—ì„œ kafka vm í†µì‹  ì²´í¬ 

```bash
$ telnet 133.186.240.216 22
Trying 133.186.240.216...
Connected to 133.186.240.216.
Escape character is '^]'.
SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.4
```

- kafka vmì—ì„œ airflow vm í†µì‹  ì²´í¬

```bash
$ telnet 133.186.155.37 22
Trying 133.186.155.37...
Connected to 133.186.155.37.
Escape character is '^]'.
SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.4

```

### 2. vm1 - vm2's docker container 

```bash
$ nc -vz {vm2_MASTER_IP} {OPENPORT} #ë‚´ê°€ í™•ì¸í•˜ê³  ì‹¶ì€ í¬íŠ¸
```

- airflow vmì—ì„œ kafkaì˜ ì»¨í…Œì´ë„ˆ í¬íŠ¸ë¡œ ì—°ê²° í™•ì¸

```bash
nc -vz 133.186.240.216 19092
Connection to 133.186.240.216 19092 port [tcp/*] succeeded!
```

- kafka container ì•ˆì—ì„œ airflow vm

```bash
nc -vz 133.186.155.37 8080
Ncat: Version 7.92 ( https://nmap.org/ncat )
Ncat: Connected to 133.186.155.37:8080.
Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.
```


# â­ Kafka Container ì•ˆì—ì„œ bootstrap-server connect


```bash
[appuser@broker ~]$ kafka-topics --list --bootstrap-server 133.186.240.216:19092
__consumer_offsets
my-topic

[appuser@broker ~]$ kafka-topics --list --bootstrap-server broker:9092
__consumer_offsets
my-topic
```

## python Example (ìµœì¢…)

```python
AwaitKafkaMessageOperator
ConsumeFromTopicOperator
    pip install apache-airflow-providers-apache-kafka==1.3.1
ProduceToTopicOperator
    pip install apache-airflow-providers-apache-kafka==1.3.1
PythonOperator
```

kafka-console-producer --topic my-topic --bootstrap-server 133.186.240.216:19092

kafka-console-consumer --topic my-topic --bootstrap-server 133.186.240.216:19092

```python
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from kafka import KafkaProducer, KafkaConsumer
from kafka.admin import KafkaAdminClient, NewTopic
from datetime import datetime
from airflow.models import TaskInstance

# Define Kafka broker
bootstrap_servers = '133.186.240.216:19092'
topic_name = 'airflowtopic6'

# Function to create Kafka topic
def create_topic():
    admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)
    topic = NewTopic(name=topic_name, num_partitions=1, replication_factor=1)
    admin_client.create_topics([topic])

# Function to check if Kafka is connected
def check_connected():
    try:
        producer = KafkaProducer(bootstrap_servers=bootstrap_servers)
        consumer = KafkaConsumer(topic_name, bootstrap_servers=bootstrap_servers)
        return True
    except Exception as e:
        print(f"Error connecting to Kafka: {str(e)}")
        return False

# Function to produce a message to Kafka
def produce_message():
    producer = KafkaProducer(bootstrap_servers=bootstrap_servers)
    message = f"Hello from Airflow. Message produced at {datetime.now()}"
    producer.send(topic_name, message.encode())
    producer.flush()

# Function to consume a message from Kafka
def consume_message(**context):
    consumer = KafkaConsumer(topic_name, bootstrap_servers=bootstrap_servers, auto_offset_reset='earliest')
    try:
        message = next(consumer)
        print(f"Message consumed: {message.value.decode()}")
        # Mark the task as success
        context['task_instance'].log.info("Message consumed successfully")
        context['task_instance'].state = "success"
    except StopIteration:
        # No message available, mark the task as failed
        context['task_instance'].log.info("No message available to consume")
        context['task_instance'].state = "failed"
    finally:
        # Close the consumer to release resources
        consumer.close()



# Function to finish
def finish():
    print("All tasks completed.")

# Define the DAG
default_args = {
    'owner': 'admin',
    'depends_on_past': False,
    'start_date': datetime(2024, 2, 7),
    'retries': 1,
}

dag = DAG(
    'airflow_kafka_interworking',
    default_args=default_args,
    description='DAG for testing interworking of Airflow and Kafka',
    schedule_interval=None,
)

# Define tasks
create_topic_task = PythonOperator(
    task_id='create_topic',
    python_callable=create_topic,
    dag=dag,
)

check_connected_task = PythonOperator(
    task_id='check_connected',
    python_callable=check_connected,
    dag=dag,
)

produce_message_task = PythonOperator(
    task_id='produce_message',
    python_callable=produce_message,
    dag=dag,
)

consume_message_task = PythonOperator(
    task_id='consume_message',
    python_callable=consume_message,
    dag=dag,
)

finish_task = PythonOperator(
    task_id='finish',
    python_callable=finish,
    dag=dag,
)

# Define task dependencies
create_topic_task >> check_connected_task >> produce_message_task >> consume_message_task >> finish_task

```
---
# ë~
#### ì‚´í´ë³´ë©´ ì¢‹ì€ ê¸€ ref: [kafkaì˜ ë°ì´í„° ì €ì¥](https://gunju-ko.github.io/kafka/2019/03/16/%EC%B9%B4%ED%94%84%EC%B9%B4%EA%B0%80%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC%EC%A0%80%EC%9E%A5%ED%95%98%EB%8A%94%EB%B0%A9%EB%B2%95.html)

> ë§ˆì¹˜ë©°..
```
networkê°€ ì–´ë–»ê²Œ ëŒì•„ê°€ëŠ”ì§€ ì´ë¯¸ì§€ë¥¼ ì—°ìƒí•˜ì—¬ ë£¨íŠ¸ë¥¼ ê·¸ë ¤ ë³¼ ê²ƒ.
í†µì‹  í…ŒìŠ¤íŠ¸ë¥¼ í•˜ëŠ” workflowë¥¼ ë³´ê³  ìˆìœ¼ë‹ˆ ì¼ë‹¨ ë‚´ë¶€ ì•„ì´í”¼ë¡œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ í•˜ë ¤ëŠ” ì‹œë„ë„ ìˆê³ , ì™¸ë¶€ ì•„ì´í”¼ê°€ ì–´ë””ì„œ ì“°ì´ëŠ”ì§€, ì–´ë–¤ê±¸ ëŒ€ë³€í•˜ëŠ”ì§€ë„ ì˜ ëª°ëë˜ ê²ƒ ê°™ìŒ.
ì™¸ë¶€ì—ì„œ ì ‘ê·¼ í•  ìˆ˜ ìˆëŠ” public ipëŠ” í•´ë‹¹ vmì˜ ë‚´ë¶€ ì•„ì´í”¼ë¥¼ ëŒ€ë³€ í•˜ëŠ” ê²ƒ ì´ë‹¤.
airflowë‚˜ kafkaë‚˜ ì„¤ì • í•˜ëŠ” ê²ƒì€ ê·¸ë‹¥ ì–´ë µì§€ ì•Šì•˜ëŠ”ë° ë„¤íŠ¸ì¿¼ê·¸ê°€ ë¬¸ì œë¼ê³  ìƒê°í–ˆì§€..ã…‹
ê·¸ë¦¬ê³  python ê°„ë‹¨í•œ ì˜ˆì œëŠ” ë§Œë“¤ ìˆ˜ ìˆëŠ” ì •ë„ë¡œ ë°°ìš°ê³  ì‹¶ë‹¤. gtpë§ê³  ã… ã… 
```
