---

---
## Project Name: 
#### Date: 2024-01-12 09:04 
#### Tag: #kugeedge_nginx
##### ref:
---
## *그런데,,나는 지금까지 daemon으로 떠있는줄 알고 `keadm` 명령어를 쓰고 로컬의 `/etc/kubeedge/config` 에서 편집하고 작업하고 ,,,, 그런데 `kubeedge` 네임스페이스에 Pod로 떠있음 ..ㅠ 그래서 설정값이나 이런 진행들이 다 pod로 이루어져야하고  `Configmap` 수정을 해야함.. 내가 진행한 대로 하면 되긴 한디 ... ^^ 몰한거지 (2024/01/12 15시52분..) 

## Nginx test
- *MasterNode* Nginx 배포
```bash
NAME                                       READY   STATUS              RESTARTS      AGE
pod/nfs-pod-provisioner-6d7bb66d56-bmgnv   1/1     Running             3 (47h ago)   47h
pod/nginx-deployment-67884b469c-6thj4      0/1     ContainerCreating   0             16h

NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes      ClusterIP   10.233.0.1      <none>        443/TCP        47h
service/nginx-service   NodePort    10.233.44.103   <none>        80:31113/TCP   16h

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nfs-pod-provisioner   1/1     1            1           47h
deployment.apps/nginx-deployment      0/1     1            0           16h

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nfs-pod-provisioner-6d7bb66d56   1         1         1       47h
replicaset.apps/nginx-deployment-67884b469c      1         1         0       16h
```
### issue 1: Nginx 상태가 ContainerCreating에 머물러 있음
> *MasterNode* 에서 Kubeproxy, nginx pod log
```bash
Error from server: Get "https://172.16.11.79:10350/containerLogs/default/nginx-deployment-67884b469c-6thj4/nginx?follow=true": dial tcp 172.16.11.79:10350: connect: connection refused
```

> *EdgeNode* edgecore log
```bash
"Error syncing pod, skipping" err="failed to \"CreatePodSandbox\" for \"nginx-depl
oyment-67884b469c-6thj4_default(83566754-e11e-428e-99d0-4616013a404c)\" with CreatePodSandboxError: \"Failed to create sandbox for pod \\\"nginx-deployment-67884b469c-6th
j4_default(83566754-e11e-428e-99d0-4616013a404c)\\\": rpc error: code = Unknown desc = cri-o configured with systemd cgroup manager, but did not receive slice as parent:
/kubepods/besteffort/pod83566754-e11e-428e-99d0-4616013a404c\"" pod="default/nginx-deployment-67884b469c-6thj4" podUID=83566754-e11e-428e-99d0-4616013a404c
```

> *MasterNode* Nginx 상태: ContainerCreating에 머물러 있음.
```bash
NAME                                       READY   STATUS              RESTARTS      AGE
pod/nfs-pod-provisioner-6d7bb66d56-bmgnv   1/1     Running             3 (47h ago)   47h
pod/nginx-deployment-67884b469c-6thj4      0/1     ContainerCreating   0             16h

NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
service/kubernetes      ClusterIP   10.233.0.1      <none>        443/TCP        47h
service/nginx-service   NodePort    10.233.44.103   <none>        80:31113/TCP   16h

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nfs-pod-provisioner   1/1     1            1           47h
deployment.apps/nginx-deployment      0/1     1            0           16h

NAME                                             DESIRED   CURRENT   READY   AGE
replicaset.apps/nfs-pod-provisioner-6d7bb66d56   1         1         1       47h
replicaset.apps/nginx-deployment-67884b469c      1         1         0       16h
```

#### Do
1.  config 설정값 변경
    1. *EdgeNode* crio.conf
        1. `cgroup_manager = "systemd"` 주석 해제
    2. *MasterNode* `/var/lib/kubelet/kubeadm-flags.env`
        1. `--cgroup-manager=systemd` 추가
    - ref
        - [config설정](https://stackoverflow.com/questions/62408028/kubelet-failed-to-createpodsandbox-for-coredns-failed-to-set-bridge-addr-c)
        - [crio default podnetwork](https://github.com/cri-o/cri-o/blob/main/tutorials/kubeadm.md)
    ![[스크린샷 2024-01-12 오전 11.15.01.png]]

2.  ~~*masternode* `/etc/cniønet.d/87-podman-bridge.conflist` 수정~~ 
    - ref
        - [cni configure](https://www.airplane.dev/blog/troubleshooting-failed-to-create-pod-sandbox-error)
-  `bridge` 를 `bridg`, `cni-poman0`을 `cni-poman`으로 변경 
    ![[스크린샷 2024-01-12 오후 1.28.42.png]]
- running상태가 뜨긴 함..  (무슨 상관이지 )  **📌 SOLVED**
    ![[스크린샷 2024-01-12 오후 1.34.47.png]]

3. *MasterNode* *EdgeNode* config yaml파일 설정값 변경
> 근데 요거는 EdgeNode에서 로그를 볼 수 없는데 로그를 보고 싶으면 `kubectl logs` 를 쓸 수 있게  진행 하는 절차임. 안해도 무방하다!
- `$ export CLOUDCOREIPS="133.186.251.185"`
- `$ iptables -t nat -A OUTPUT -p tcp --dport 10350 -j DNAT --to $CLOUDCOREIPS:30003`
- 각 config yaml의 `cloudStream`, `edgeStream`을 `enable: true`로 바꿔줌
    ![[스크린샷 2024-01-12 오후 2.00.30.png]]
    ![[스크린샷 2024-01-12 오후 2.01.15.png]]

### issue 2: edgemesh를 사용하기 위해서는 kube-proxy를 쓰지 않는다?
ref: chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://readthedocs.org/projects/kubeedge/downloads/pdf/latest/
#### 해결
- *MasterNode* kube-proxy daemonset에 아래를 추가
> spec.affinty
```yaml
affinity: 
  nodeAffinity: 
    requiredDuringSchedulingIgnoredDuringExecution: 
      nodeSelectorTerms:
      - matchExpressions:
        - key: node-role.kubernetes.io/edge 
          operator: DoesNotExist
```
- *EdgeNode* edgecore.service에서 proxy 관련은 에러가 없어졌음. 

## Nginx issue 해결 후 통신 체크

1. Curl pod 배포 
- [[Curl test Pod]]
    🥲 진짜 웃김.. 나는 이 파드가 자꾸 왜 edge에 배포되는지 궁금해서 Do의 2번 작업을 해주었던 것인데.... ㅋ edge도 클러스터중 하나의 노드이니까 당연히 배포될 수 있자너..? 바보다.. ㅋ 
    ![[스크린샷 2024-01-12 오후 2.27.37.png]]
    ![[스크린샷 2024-01-12 오후 2.29.49.png]]
    아무튼 그래서  curl pod를 nodeselector로 지정하여 Edge에 배포 안되게 다시 재배포 고고.
- 배포: 될 리가 없쥬
    ![[스크린샷 2024-01-12 오후 2.58.15.png]]

## 이제는 EdgeMesh 할 차례
> 위와 관련하여 Pod 안에서도 통신을 할 수 있게  'edgeMesh'를 진행하게 된다 

kubectl taint nodes --all node-role.kubernetes.io/control-plane
```
kubectl label services kubernetes service.edgemesh.kubeedge.io/service-proxy-name="edgemesh"
```


```
keadm init --advertise-address="133.186.251.185" --profile version=v1.15.1 --kube-config=/root/.kube/config --set cloudCore.modules.dynamicController.enable=true
```
133.186.212.168
### Pod로 갑자기 진행하기
- Cloudcore의 configmap
```yaml
apiVersion: v1
data:
  cloudcore.yaml: "apiVersion: cloudcore.config.kubeedge.io/v1alpha2\nkind: CloudCore\nkubeAPIConfig:\n
    \ kubeConfig: \"\"\n  master: \"\"\nmodules:\n  cloudHub:\n    advertiseAddress:\n
    \   - 133.186.251.185\n    dnsNames:\n    - \n    nodeLimit: 1000\n    tlsCAFile:
    /etc/kubeedge/ca/rootCA.crt\n    tlsCertFile: /etc/kubeedge/certs/edge.crt\n    tlsPrivateKeyFile:
    /etc/kubeedge/certs/edge.key\n    unixsocket:\n      address: unix:///var/lib/kubeedge/kubeedge.sock\n
    \     enable: true\n    websocket:\n      address: 0.0.0.0\n      enable: true\n
    \     port: 30000\n    quic:\n      address: 0.0.0.0\n      enable: false\n      maxIncomingStreams:
    10000\n      port: 30001\n    https:\n      address: 0.0.0.0\n      enable: true\n
    \     port: 30002\n  cloudStream:\n    enable: true\n    streamPort: 30003\n    tunnelPort:
    10004\n  dynamicController:\n    enable: true\n  router:\n    enable: false\n
    \ iptablesManager:\n    enable: true\n    mode: internal\n  nodeUpgradeJobController:\n
    \   enable: false\n"
kind: ConfigMap
metadata:
  annotations:
    meta.helm.sh/release-name: cloudcore
    meta.helm.sh/release-namespace: kubeedge
  creationTimestamp: "2024-01-11T05:27:33Z"
  labels:
    app.kubernetes.io/managed-by: Helm
    k8s-app: kubeedge
    kubeedge: cloudcore
  name: cloudcore
  namespace: kubeedge
  resourceVersion: "443867"
  uid: 34be17b8-9906-46bf-98cf-12759c9ae3fb
```
- 수정 후 진행
```bash
kubectl rollout restart deploy cloudcore
```
- 보기 어려워서 Yaml로 바꿔서 눈에 보이기 쉽게 해봄 
```yaml
cloudcore.yaml: |
  apiVersion: cloudcore.config.kubeedge.io/v1alpha2
  kind: CloudCore
  kubeAPIConfig:
    kubeConfig: "/root/.kube/config"
    master: ""
  modules:
    cloudHub:
      advertiseAddress:
        - 133.186.251.185
      dnsNames:
        - 
      nodeLimit: 1000
      tlsCAFile: /etc/kubeedge/ca/rootCA.crt
      tlsCertFile: /etc/kubeedge/certs/edge.crt
      tlsPrivateKeyFile: /etc/kubeedge/certs/edge.key
      unixsocket:
        address: unix:///var/lib/kubeedge/kubeedge.sock
        enable: true
      websocket:
        address: 0.0.0.0
        enable: true
        port: 30000
      quic:
        address: 0.0.0.0
        enable: false
        maxIncomingStreams: 10000
        port: 30001
      https:
        address: 0.0.0.0
        enable: true
        port: 30002
    cloudStream:
      enable: true
      streamPort: 30003
      tunnelPort: 30004
    dynamicController:
      enable: true
    router:
      enable: false
    iptablesManager:
      enable: true
      mode: internal
    nodeUpgradeJobController:
      enable: false
```