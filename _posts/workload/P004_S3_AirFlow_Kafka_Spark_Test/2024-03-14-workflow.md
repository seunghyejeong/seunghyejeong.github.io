---

---
## Project Name: pipeline 작성. dags/tasks 나누기 
#### Date: 2024-03-14 11:10 
#### Tag:
---
# Contents:

- [b] REF
>


# File import error 

- 다른 폴더에 있는 파일을 불러오는 것에 에러가 자주 남.
- 파일 구조는 이와 같음
```
- dags
---- iot.py
- dowork
---- kafka_task.py
---- spark_task.py
---- store_task.py
```

1. `print(sys.path)`를 출력해본다.
```
['/opt/airflow/dags', '/usr/local/lib/python38.zip', '/usr/local/lib/python3.8', '/usr/local/lib/python3.8/lib-dynload', '/home/airflow/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/site-packages', '/opt/airflow/config', '/opt/airflow/plugins', '/opt/airflow/dowork']
```

> GPT에서 받은 정보
> 
> 2. To configure your Python script `iot.py` to import modules from the `dowork` directory correctly, let's go through the steps:
>
    2-1. **Add `dowork` Directory to Python Path**: Ensure that you're adding the correct path to the `dowork` directory. Since both `dags` and `dowork` directories are in the same parent directory (`airflow`), you should append the parent directory to the Python path. Modify your script like this:
>
> [pythonCopy code]
```python
import sys
import os

# Get the parent directory of the current file (iot.py)
current_dir = os.path.dirname(os.path.realpath(__file__)) < 현재 경로 추가 
airflow_dir = os.path.abspath(os.path.join(current_dir, os.pardir)) < 현재 경로와 상위 경로를 추가 

# Add the parent directory to the Python path
sys.path.append(airflow_dir)

# Now you can import modules from the dowork directory
from dowork import kafka_task, spark_task, store_task

```
  >  
    2-2. **Verify Directory Names and Spelling**: Double-check that the directory names and the module names are spelled correctly and match the import statements exactly. Ensure there are no typos.
  >  
    2-3. **Ensure `dowork` Directory Contains `__init__.py` File**: Create an empty `__init__.py` file in the `dowork` directory if it doesn't already exist. This file is necessary to indicate to Python that the directory should be treated as a package.
>    
    2-4. **Check File Permissions**: Ensure that the `dowork` directory and its contents have the necessary permissions for the user running the Python script to read the files.
>    
    2-5 **Restart Airflow**: After making these changes, restart the Airflow scheduler and workers to apply the configuration changes.
  >  
>
    By following these steps, you should be able to configure your Python script `iot.py` to import modules from the `dowork` directory successfully. Let me know if you encounter any issues or if you need further assistance!

: 해석을 해보니 `/opt/airflow/dags`와 `/opt/airflow/dowork`의 폴더 경로까지는 나도 등록을 했지만 잘 작용 하지 않았다. 이유는 `dags`와 `dowork`의 parents 폴더인 `airflow`가 등록 되어 있지 않아서. 그래서 `curreint_dir`과 `os.pardir`(즉 /opt/airflow) 를 경로에 함께 추가 시킨다. 

여기까지 해주니 local 환경 에서는 잘 동작 되었다. 하지만 airflow ui에서는 또 제대로 작동하지 않는다. ㅠ
이유는 경로의 권한 때문인데, 다른 경로는 다 root 였지만 새로 생성한 `dowork`는 airflow 권한이었다. 
image를 말 때 생성 하는걸로 하고, 테스트는 같은 dir 에서 해야겠다. 

