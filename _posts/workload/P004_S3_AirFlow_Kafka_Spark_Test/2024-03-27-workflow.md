```
125.6.40.10
```





        .config('spark.jars', './jars/spark-sql-kafka-0-10_2.12-3.3.0.jar')\
        .config("spark.sql.execution.arrow.pyspark.enabled", "true")\
vi 



--conf "spark.driver.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties" \
--conf "spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties" \
--files "/opt/bitnami/spark/conf/log4j2.properties" \
/opt/bitnami/spark/msg.py
>



        .option("group.id", "console-consumer-43849")\

curl -X PUT -H 'X-Auth-Token: gAAAAABmA7tWC8j2RX_9CE416POkHO-B14e4fdf12MQgjmqH9dODWtiYHfdd3hHykPDMc5ZSLdcNPIGUT-EQScSzNVtV7k5VWm74CuoOE4f5HbM2Zpt6_LNSWpMB25Ew8-kbuxADEZ3ob_50uyA18yiQzp6nsFlLoBE1QGOAFzbCWLAy4_epdx0' \ https://kr1-api-object-storage.nhncloudservice.com/v1/AUTH_9ea3a098cb8e49468ac2332533065184/cp-object-storage \ -T ./*json


https://codesandbox.io/p/github/peccu/spark-hdfs/main?file=%2Fcompose.yml%3A29%2C1

v55.5.0
grafana 7.0.17
prometheus-node-exporter 4.24.0