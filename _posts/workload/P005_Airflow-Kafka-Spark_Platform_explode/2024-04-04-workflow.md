---

---
## Project Name:  airflow dag 초안 
#### Date: 2024-04-04 09:25 
#### Tag:
---
# Contents:


```
125.6.37.91
```

```Dockerfile
FROM apache/airflow:2.8.4-python3.10

ENV AIRFLOW_HOME=/opt/airflow
ENV JAVA_HOME=/usr/lib/jvm/jdk1.8.0_401
ENV PATH="$PATH:${AIRFLOW_HOME}/bin:${JAVA_HOME}/bin"

USER root

RUN mkdir /usr/lib/jvm
COPY jdk-11.0.0.1.tar.gz /opt/airflow
RUN tar xvf jdk-11.0.0.1.tar.gz -C /usr/lib/jvm \
	&& rm jdk-11.0.0.1.tar.gz

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        vim \
        wget \
        net-tools \
        dnsutils \
        iputils-ping \
        netcat-openbsd \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

USER airflow
COPY requirements.txt /
COPY ./dags /opt/airflow/dags
RUN pip install --no-cache-dir "apache-airflow==${AIRFLOW_VERSION}" -r /requirements.txt
```

ProduceToTopicOperator

```python
import datetime as dt
from datetime import timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from kubernetes.client import models as k8s
import uuid

default_args = {
    'owner': 'admin',
    'depends_on_past': False,
    'start_date': dt(2024, 1, 1),
    'retries': 1,
    'provide_context': True,
    'retry_delay': timedelta(minutes=1)
}

with DAG(
    dag_id='pipeline',
    default_args=default_args,
    schedule_interval=None
    ) as dag:

    replicas = k8s.V1ReplicaSetSpec(replicas=1)

    send_to_kafka_message = KubernetesPodOperator(
        kubernetes_conn_id="kubernetes_default",
        task_id="send_to_kafka_message",
        name="kafka-topic",
        namespace="kafka",
        replicas=replicas,
        arguments=["kubectl apply -f /home/ubuntu/kafka-topic.yaml"],
        get_logs=True,
        dag=dag,
        is_delete_operator_pod=False,
    )


    full_container_spec = k8s.V1Container(
        image="confluentinc/cp-kafka:7.6.0",
        command=["sh", "-c", "exec tail -f /dev/null"],
    )

    deploy_kafka_client = KubernetesPodOperator(
        kubernetes_conn_id="kubernetes_default",
        name="kafka-client",
        task_id = "deploy_kafka_client",
        dag=dag,
        namespace="kafka",
        get_log=True,
        is_delete_operator_pod=False,
        full_container_spec=full_container_spec,
    )

    streaming_kafka_message = KafkaProducerOperator(
        task_id='streaming_kafka_message',
        topic='kafka-topic',
        bootstrap_servers='125.6.37.91:19092',
        messages=["Message 1", "Message 2", "Message 3"],
        dag=dag,
    )
```

- [*] 파라미터 값 변경 
`from airflow.providers.cncf.kubernetes.operators.pod import KubernetesPodOperator` ➡️
`from airflow.providers.apache.kafka.operators.produce import ProduceToTopicOperator` 


---


어찌저찌 코드 에러를 없애며 완성 시켰다
1. replicas는 `KubernetesPodOperator`에 컨피그 값으로 들어가있기 때문에 다른 클래스를 import 하거나 그럴 필요 없었다
2. full_container_spec 은 `KubernetesPodOperator`안에서도 지정 할 수 있는 파라미터 값이 있다.
3. ProduceToTopicOperator에는 `bootstrap_server`가 없다.

배포과정 
1. kubernetes에 접근하기 위해서는 kubeconfig 파일이 있어야 하는데, 컨테이너 안에 있어야한다.
    1. kubernetes config를 secret로 변경해서 컨테이너에 넣어주기 
        1. `cat /home/ubuntu/.kube/kubeconfig | base64`
        2. 변환된 config파일로 secret 만들기 
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: kubeconfig-secret
type: Opaque
data:
  kubeconfig: |
    0emFrUm9SR3BtTlVNNGRG(생략)
```

---

conn_id
conn_type
in_cluster
는 중복 될 수 없

config_file=/home/ubuntu/.kube/config 