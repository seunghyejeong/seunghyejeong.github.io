---

---
## Project Name: dag 배포 
#### Date: 2024-04-05 11:04 
#### Tag:
---
# Contents:

## airflow에 대한 권한 할당

- 앞서 , [[002Report/4월/2024-04-04|2024-04-04]]에서 발생한 conn_id,in_cluster 중복 된 값을 쓸 수 없고 셋 중에 하나만 쓰라고 한 오류가 발생함. 
```
airflow.exceptions.AirflowException: Invalid connection configuration. Options kube_config_path, kube_config, in_cluster are mutually exclusive. You can only use one option at a time.
```

- 이 떄 kubernetes_default connection도 만들어진 상태고 , kubeconfig도 지정된 상태였음.
- 그래서 kubernetes connection을 없애고 `in_cluster=False`로 변경
- 그러면 airflow는 local환경에서 config파일을 찾게 되고 kubernetes config파일은 default로 `~/.kube/config`로 지정되어 있어서 올바른 루트를 찾게됨

### airflow-worker에 대한 Cluster Role 생성

- 만난 오류 
```
HTTP response headers: HTTPHeaderDict({'Audit-Id': 'ed0a47ea-12be-4cd3-9282-322c8da66c41', 'Cache-Control': 'no-cache, private', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'X-Kubernetes-Pf-Flowschema-Uid': 'dcc218f1-87e4-4b1b-8a24-7f7e971499e9', 'X-Kubernetes-Pf-Prioritylevel-Uid': 'aa260997-750b-4cc2-b59e-58dc3ed9d65e', 'Date': 'Fri, 05 Apr 2024 00:51:16 GMT', 'Content-Length': '287'}) HTTP response body: {"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"pods is forbidden: User \"system:serviceaccount:airflow:airflow-worker\" cannot list resource \"pods\" in API group \"\" in the namespace \"kafka\"","reason":"Forbidden","details":{"kind":"pods"},"code":403} [2024-04-05, 00:51:16 UTC] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=pipeline, task_id=deploy_kafka_client, execution_date=20240405T004948, start_date=20240405T005116, end_date=20240405T005116 [2024-04-05, 00:51:16 UTC] {standard_task_runner.py:107} ERROR - Failed to execute job 35 for task deploy_kafka_client ((403) Reason: Forbidden
```

이 오류는 airflow가 kafka의 namespace에 접근 할 수 없다는 것.

1. 모든 권한에 접근 가능한 cluster-Role을 생성
2. 위의 오류에 나타난 Service Account에게 Cluster Role을 부여한다.
```yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: airflow-kafka-connect-cluster-role
rules:
- apiGroups: ["*"]
  verbs: ["*"]
  resources: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: airflow-kafka-connect-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: airflow-kafka-connect-cluster-role
subjects:
- kind: ServiceAccount
  name: airflow-worker
  namespace: airflow
```


# Dag의 무한 로딩

- kafka-client
```
    command:
      - sh
      - -c
      - "exec tail -f /dev
```

이 커맨드는 container가 계속 실행되게 하는 command인데 이를 dag으로 정의했다 

```
    deploy_kafka_client = KubernetesPodOperator(
        image="confluentinc/cp-kafka:7.6.0",
        name="kafka-client-sub",
        task_id = "deploy_kafka_client",
        dag=dag,
        namespace="kafka",
        get_logs=True,
        is_delete_operator_pod=True,
        cmds=["sh", "-c", "exec tail -f /dev/null"],
        in_cluster=False
    )
```

그랬더니 컨테이너가 계속 실행중이기 때문에 파드가 정상적을 배포되고 실행중임에도 불구하고 상태가 완료로 뜨지도 않고 airflow job이 running으로 뜨면서 다음 job으로 넘어가지 않는 상황이 발생함.


방법을 좀 더 찾아봐야 할 것 같음..


## resource.zip
### Airflow
#### dag
- dags.py

```yaml
from airflow.providers.apache.kafka.operators.produce import ProduceToTopicOperator
from airflow.providers.cncf.kubernetes.operators.pod import KubernetesPodOperator
from datetime import datetime as dt
from datetime import timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator
from kubernetes.client import models as k8s
from kubernetes.client.models import V1ReplicaSetSpec, V1LabelSelector, V1LabelSelectorRequirement
import pendulum

local_tz = pendulum.timezone("Asia/Seoul")

def update_dag_run_state_to_success(dag_id, execution_date):
    dag_run = DagRun.find(dag_id=dag_id, execution_date=execution_date)
    if dag_run:
        dag_run[0].state = 'success'
        dag_run[0].end_date = datetime.utcnow()
        dag_run[0].session.commit()

default_args = {
    'owner': 'admin',
    'depends_on_past': False,
    'start_date': dt(2024, 1, 1, tzinfo=local_tz),
    'retries': 1,
    'provide_context': True,
    'retry_delay': timedelta(minutes=1)
}

with DAG(
    dag_id='pipeline',
    default_args=default_args,
    schedule_interval=None
    ) as dag:

    deploy_kafka_client = KubernetesPodOperator(
        image="confluentinc/cp-kafka:7.6.0",
        name="kafka-client-sub",
        task_id = "deploy_kafka_client",
        dag=dag,
        namespace="kafka",
        get_logs=True,
        is_delete_operator_pod=True,
        cmds=["sh", "-c", "exec tail -f /dev/null"],
        in_cluster=False,
        on_success_callback=success_callback,
    )

    command = "kubectl apply -f /home/ubuntu/kafka/kafka-topic.yaml"

    deploy_kafka_topic = BashOperator(
        task_id='deploy_kafka_topic',
        bash_command=command,
        dag=dag,
    )

    def message():
        return [{"eventId": "3448694a-56b1-43c0-a93e-99c1915dd910", "eventOffset": 103, "eventPublisher": "device", "data": {"devices": [{"deviceId": 4, "name": "ji", "age": 35}]}, "eventTime": "2024-03-22 10:10:51.777997"}]

    streaming_kafka_message = ProduceToTopicOperator(
        kafka_config_id="kafka_default",
        producer_function=message,
        task_id='streaming_kafka_message',
        topic='kafka-topic',
        dag=dag,
    )

    deploy_kafka_client >> deploy_kafka_topic >> streaming_kafka_message
```

### airflow- custom_values_2.yaml 

```yaml
images:
  airflow:
    repository: seunghyejeong/airflow_v2
    tag: "1.0"
    digest: ~
    pullPolicy: IfNotPresent

# Load Examples
extraEnv: |
  - name: AIRFLOW__CORE__LOAD_EXAMPLES
    value: 'False'
  - name: AIRFLOW__CORE__DEFAULT_TIMEZONE
    value: 'Asia/Seoul'
#set executor
executor: "KubernetesExecutor"

# Webserver configure
webserver:
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: user
    password: admin
  service:
    type: NodePort
    ports:
      - name: airflow-ui
        port: 8080
        targetPort: 8080
        nodePort: 31151
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  extraVolumeMounts:
    - name: airflow-dags
      mountPath: /opt/airflow/dags
    - name: kubeconfig-volume
      mountPath: /opt/airflow/.kube/kubeconfig
      readOnly: true
  extraVolumes:
    - name: airflow-dags
      persistentVolumeClaim:
        claimName: airflow-dags
    - name: kubeconfig-volume
      secret:
        secretName: kubeconfig-secret

# bind w strogaeClass
dags:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
    accessMode: ReadWriteMany
    size: 5Gi
workers:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
    size: 5Gi
logs:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
triggerer:
  persistence:
    enabled: true
    size: 5Gi
    storageClassName: cp-storageclass

```

```Dockerfile
FROM apache/airflow:2.8.4-python3.10

ENV AIRFLOW_HOME=/opt/airflow
ENV JAVA_HOME=/usr/lib/jvm/jdk1.8.0_401
ENV PATH="$PATH:${AIRFLOW_HOME}/bin:${JAVA_HOME}/bin"

USER root

RUN mkdir /usr/lib/jvm && mkdir ./.kube
COPY jdk-11.0.0.1.tar.gz /opt/airflow
RUN tar xvf jdk-11.0.0.1.tar.gz -C /usr/lib/jvm \
	&& rm jdk-11.0.0.1.tar.gz
COPY /home/ubuntu/.kube/kubeconfig /opt/airflow/.kube/kubeconfig

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        vim \
        wget \
        net-tools \
        dnsutils \
        iputils-ping \
        netcat-openbsd \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

USER airflow
COPY requirements.txt /
COPY ./dags /opt/airflow/dags
RUN pip install --no-cache-dir "apache-airflow==${AIRFLOW_VERSION}" -r /requirements.txt

```

### clusterRole
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: airflow-kafka-connect-cluster-role
rules:
- apiGroups: ["*"]
  verbs: ["*"]
  resources: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: airflow-kafka-connect-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: airflow-kafka-connect-cluster-role
subjects:
- kind: ServiceAccount
  name: airflow-kafka-connect
  namespace: airflow
```

+ jar파일 필요
### requirements.txt

```txt
apache-airflow-providers-apache-kafka==1.3.1
confluent-kafka~=2.3.0
apache-airflow-providers-apache-spark==4.7.1
py4j==0.10.9.5
grpcio-status>=1.59.0
apache-airflow-providers-cncf-kubernetes==8.0.1
kubernetes==29.0.0
```

## Kafka
### kafka-client
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: kafka-client
  namespace: kafka
spec:
  containers:
  - name: kafka-client
    image: confluentinc/cp-kafka:7.6.0
    command:
      - sh
      - -c
      - "exec tail -f /dev/null"

```

### kafka-deploy

```yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: bami
  namespace: kafka
spec:
  kafka:
    version: 3.6.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: nodeport
        tls: false
      - name: tls
        port: 9093
        type: nodeport
        tls: false
    config:
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 1
      default.replication.factor: 1
      min.insync.replicas: 1
      inter.broker.protocol.version: "3.6"
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
```

### kafka - topic

```yaml
kind: KafkaTopic
metadata:
  name: kafka-topic
  namespace: kafka
  labels:
    strimzi.io/cluster: "bami"
spec:
  replicas: 1
  partitions: 1
  config:
    retention.ms: 7200000
    segment.bytes: 1073741824
    min.insync.replicas: 2
```

### helm repo 
helm repo add strimzi https://strimzi.io/charts/  
helm repo update

