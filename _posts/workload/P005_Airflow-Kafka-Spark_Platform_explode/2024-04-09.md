---

---
## Project Name: kubernetes ê¶Œí•œ ìƒì„±, kafka ë§ˆìš´íŠ¸ , í† í”½ìƒì„± 
#### Date: 2024-04-09 09:20 
#### Tag: #kubernetesuser #airflowDockerfile0409
---
# Contents:

1.  airflow namespace ìƒì„±
2. user account ìƒì„±
    - private key ìƒì„±
```
openssl genrsa -out airflow.key 2048
```
    
    - crt ìƒì„±ì„ ìœ„í•œ csr 
```
openssl req -new -key test-user.key -out test-user.csr
```

- csrë¥¼ ìœ„í•œ cert ìƒì„± 
```
cat test-user.csr | base64 -w 0
```

```
LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ25EQ0NBWVFDQVFBd1Z6RUxNQWtHQTFVRUJoTUNTMUl4RXpBUkJnTlZCQWdNQ2xOdmJXVXRVM1JoZEdVeApJVEFmQmdOVkJBb01HRWx1ZEdWeWJtVjBJRmRwWkdkcGRITWdVSFI1SUV4MFpERVFNQTRHQTFVRUF3d0hZV2x5ClpteHZkekNDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQkFNZkp0R1hqTmpPeHM2VlIKWmJVaURrRGJtZ0pFenRBVzFjSkpZaldad3BFSjREYjNkRllTZUZXSmE3WWxTUi95SS9WbHd3MHpjSVd3eHR1RApKdnRlRGhvakNwZ0sxM0oxNmJ2TXFpdVlKTEtOLzlpUUZWMnMxSS8rSi9ta3RoTjJQMGJvT3UzYWg2dTZHVEdKClhIc3k0T09RWHZHcjUxM2EwYVdnWVFENzJTYlplZFM5NHFWZG1BcDY4T2I5cWw0azVxaDVEbzFYaEZ1dkVFMG4KbStneUlKM3BhS3RSakI1aitPNHVKRkJ3UHFYSkozTFpoc3RUVHpMOXFJdDFzZ1htdnRNanF4Mm93UHVRR25DMgpyQ0E4TTFURFVkVzFFZXJtbk9OUzNtUExmZmhwd2NHdC9VUGFaOGM4Y0xGTy9yVStzUXcrQU8rdUQzYjFmYlR1CmxTUVRmNlVDQXdFQUFhQUFNQTBHQ1NxR1NJYjNEUUVCQ3dVQUE0SUJBUUE0Mkl6Qlpsc2w5MzNneE82UGRsSTEKOC9qK054VnFEZzdaRXNIV04wYUQvSXFiS0JDa1dlN0F3cUFYcnFCK2JLbmY2QTUyRFA3UVZLcXFLV2wxM3JyTwpHSE5leWJ5SHFzRE44aVExWFdLVWRqS2VGZkZ1MTFmODNIdEhrUFlla3ZJeUM0SnZmczdRQnlOQk5PbU9RZHloClVSWHRLeEgzZTV1VllFWWljUjZLYkFkOHg0SEhnRnhqcFYrcllpTHlHUDdWTkcveG9IYnc5ZzRuNEkzNzZ6TWwKcHlrMU1ZNjhUUkI4UDZOR3VySkhNUkFYenZXbUovSTZtMGljaEtZUkExQTNjTHhrd1dXSjAzT21DS0Z1MllZdwpLMXBxcmhaZWZ3NTAzL2NEUmxoc3M5U0hBVXNqSVp1d1ZEbXd4MG1aNjZmd21BSW4yT1MxN0h0OWk0cktEejRPCi0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=
```

- airflow-csr.yaml
```yaml
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: airflow
spec:
  request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ25EQ0NBWVFDQVFBd1Z6RUxNQWtHQTFVRUJoTUNTMUl4RXpBUkJnTlZCQWdNQ2xOdmJXVXRVM1JoZEdVeApJVEFmQmdOVkJBb01HRWx1ZEdWeWJtVjBJRmRwWkdkcGRITWdVSFI1SUV4MFpERVFNQTRHQTFVRUF3d0hZV2x5ClpteHZkekNDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQkFNZkp0R1hqTmpPeHM2VlIKWmJVaURrRGJtZ0pFenRBVzFjSkpZaldad3BFSjREYjNkRllTZUZXSmE3WWxTUi95SS9WbHd3MHpjSVd3eHR1RApKdnRlRGhvakNwZ0sxM0oxNmJ2TXFpdVlKTEtOLzlpUUZWMnMxSS8rSi9ta3RoTjJQMGJvT3UzYWg2dTZHVEdKClhIc3k0T09RWHZHcjUxM2EwYVdnWVFENzJTYlplZFM5NHFWZG1BcDY4T2I5cWw0azVxaDVEbzFYaEZ1dkVFMG4KbStneUlKM3BhS3RSakI1aitPNHVKRkJ3UHFYSkozTFpoc3RUVHpMOXFJdDFzZ1htdnRNanF4Mm93UHVRR25DMgpyQ0E4TTFURFVkVzFFZXJtbk9OUzNtUExmZmhwd2NHdC9VUGFaOGM4Y0xGTy9yVStzUXcrQU8rdUQzYjFmYlR1CmxTUVRmNlVDQXdFQUFhQUFNQTBHQ1NxR1NJYjNEUUVCQ3dVQUE0SUJBUUE0Mkl6Qlpsc2w5MzNneE82UGRsSTEKOC9qK054VnFEZzdaRXNIV04wYUQvSXFiS0JDa1dlN0F3cUFYcnFCK2JLbmY2QTUyRFA3UVZLcXFLV2wxM3JyTwpHSE5leWJ5SHFzRE44aVExWFdLVWRqS2VGZkZ1MTFmODNIdEhrUFlla3ZJeUM0SnZmczdRQnlOQk5PbU9RZHloClVSWHRLeEgzZTV1VllFWWljUjZLYkFkOHg0SEhnRnhqcFYrcllpTHlHUDdWTkcveG9IYnc5ZzRuNEkzNzZ6TWwKcHlrMU1ZNjhUUkI4UDZOR3VySkhNUkFYenZXbUovSTZtMGljaEtZUkExQTNjTHhrd1dXSjAzT21DS0Z1MllZdwpLMXBxcmhaZWZ3NTAzL2NEUmxoc3M5U0hBVXNqSVp1d1ZEbXd4MG1aNjZmd21BSW4yT1MxN0h0OWk0cktEejRPCi0tLS0tRU5EIENFUlRJRklDQVRFIFJFUVVFU1QtLS0tLQo=
  signerName: kubernetes.io/kube-apiserver-client
  expirationSeconds: 86400  # one day
  usages:
  - client auth
```

- kubectl get csr airflow
```
NAME      AGE   SIGNERNAME                            REQUESTOR          REQUESTEDDURATION   CONDITION
airflow   2s    kubernetes.io/kube-apiserver-client   kubernetes-admin   24h                 Pending
```

```
kubectl certificate approve airflow

certificatesigningrequest.certificates.k8s.io/airflow approved
```

- crtíŒŒì¼ì´ ìƒê¹€ 
```
kubectl get csr airflow -o jsonpath='{.status.certificate}' | base64 -d > airflow.crt
```

```
kubectl config set-credentials airflow --client-key=airflow.key --client-certificate=airflow.crt
```

```
kubectl config set-context airflow-context --cluster=kubernetes --user=airflow
```

```
kubectl config get-contexts
```

```
kubectl config use-context airflow-context
```


- kubernetes ì ‘ì† 
```
kubectl config get-contexts
CURRENT   NAME              CLUSTER      AUTHINFO   NAMESPACE
          airflow-context   kubernetes   airflow
*         cluster1          cluster1     cluster1
```


3. clusterrole ìƒì„± ë° ë°°í¬  
```yaml
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: airflow-admin-cluster-role
rules:
- apiGroups: [""]
  verbs: ["*"]
  resources: ["*"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: airflow-admin-cluster-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: airflow-admin-cluster-role
subjects:
- kind: User
  name: airflow
  namespace: airflow

```

/home/airflow/.local/bin

# ? Fernet key
```
echo Fernet Key: $(kubectl get secret --namespace airflow airflow-fernet-key -o jsonpath="{.data.fernet-key}" | base64 --decode)
Fernet Key: V1lJOGFEQWU2Q1RudVNyaVdVMEIya2VRaTJBZWVQUkc=

```

```
from datetime import datetime as dt
from datetime import timedelta
from airflow import DAG
from airflow.operators.bash_operator import BashOperator
import pendulum

local_tz = pendulum.timezone("Asia/Seoul")

default_args = {
    'owner': 'admin',
    'depends_on_past': False,
    'start_date': dt(2024, 1, 1),
    'retries': 1,
    'provide_context': True,
    'retry_delay': timedelta(minutes=1)
}

with DAG('pipeline', default_args=default_args, schedule_interval=None) as dag:
    deploy_kafka_topic = BashOperator(
        task_id='deploy_kafka_topic',
        bash_command='kubectl apply -f /opt/airflow/kafka/kafka-topic.yaml',
        dag=dag,
        )
    
    deploy_kafka_topic
```

# kubectl permission denied

ìœ ì €ë¥¼ ìƒì„± í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ì“¸ ìˆ˜ ì—†ì—ˆìŒ
ì´ìœ : kubectlì´ airflow container ì•ˆì—ì„œë„ ì“¸ ìˆ˜ ìˆì–´ì•¼í•˜ê¸° ë•Œë¬¸.

Dockerfileì„ ìˆ˜ì •í•˜ì—¬ kubectlì´ /usr/local/binì— ì„¤ì¹˜ë˜ë„ë¡ í–ˆë‹¤.
    ì²˜ìŒì—ëŠ” webserverì—ë§Œ ì„¤ì¹˜ë¥¼ í•´ì„œ kubectlì„ ì‚¬ìš©í•˜ì§€ ëª»í–ˆëŠ”ë°, ì „ ì»¨í…Œì´ë„ˆì— ë‹¤ ì„¤ì¹˜í•˜ë„ë¡ ì´ë¯¸ì§€ë¥¼ ë°”ê¿ˆ.
```Dockerfile
FROM apache/airflow:2.8.4-python3.10

ENV AIRFLOW_HOME=/opt/airflow
ENV JAVA_HOME=/usr/lib/jvm/jdk1.8.0_401
ENV PATH="$PATH:${AIRFLOW_HOME}/bin:${JAVA_HOME}/bin"

USER root

RUN mkdir /usr/lib/jvm && mkdir ./.kube
COPY jdk-11.0.0.1.tar.gz /opt/airflow
RUN tar xvf jdk-11.0.0.1.tar.gz -C /usr/lib/jvm \
	&& rm jdk-11.0.0.1.tar.gz

===
RUN sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl" && sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
=== ì´ë¶€ë¶„

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        vim \
        wget \
        net-tools \
        dnsutils \
        iputils-ping \
        netcat-openbsd \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

#RUN curl -o  /opt/airflow/jars/kafka-clients-3.5.1.jar https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.1/kafka-clients-3.5.1.jar
#RUN curl -o /opt/airflow/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.1/spark-token-provider-kafka-0-10_2.12-3.5.1.jar
#RUN curl -o /opt/airflow/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.1/spark-sql-kafka-0-10_2.12-3.5.1.jar
#RUN curl -o /opt/airflow/jars/commons-pool2-2.11.0.jar https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.0/commons-pool2-2.11.0.jar

USER airflow
COPY ./requirements.txt /
RUN pip install --no-cache-dir "apache-airflow==${AIRFLOW_VERSION}" -r /requirements.txt

```

kafkaì˜ ì‹¤í–‰ íŒŒì¼ì´ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì— ìœ„ì¹˜í•˜ê³  ìˆìœ¼ë¯€ë¡œ ëª¨ë“  podê°€ ê°™ì€ ê²½ë¡œì˜ ê°™ì€ íŒŒì¼ì„ ì ‘ê·¼ í•  ìˆ˜ ìˆì–´ì•¼í—€ë‹¤ ì¦‰  -> *ë‚´ì¡°ê±´ì€ ëª¨ë“  ì»¨í…Œì´ë„ˆì— kafka íŒŒì¼ì´ ê³µìœ  ë˜ì–´ì•¼í•˜ê³  (dagsì²˜ëŸ¼) ëª¨ë“  íŒŒë“œì— kubectlì´ ê°€ëŠ¥ í•´ì•¼ í–ˆë‹¤.*
- container ëª¨ë“  êµ¬ì—­ì— volumeì„ defaultë¡œ ì¡ì•„ì£¼ëŠ” custom-values.yamlì„ ìˆ˜ì • í•¨.
- í´ë”ëŠ” ê° containerì— ë‹¤ ìƒê²¼ë‹¤. ê·¸ëŸ¬ë‚˜ webserverì—ë§Œ íŒŒì¼ì´ ë“¤ì–´ì™€ìˆê³  ë‚˜ë¨¸ì§€ íŒŒë“œì—ëŠ” íŒŒì¼ì´ ì—†ì—ˆë‹¤.
- ë‹¤ë¥¸ì ì€ webserverë§Œ 1000 userì´ê³  ë‚˜ë¨¸ì§€ëŠ” root ì˜€ë‹¤
 ì»¨í…Œì´ë„ˆ ëª©ë¡
   - worker scheduler createUserJob migrateDatabaseJob triggerer dagProcessor, redis
- ì¼ë‹¨ kafkaë¥¼ airflowì•ˆìœ¼ë¡œ í´ë”ë¥¼ ì˜®ê²¼ë‹¤
    - dockerfileë¡œ Volumeì„ í•´ë„ ì•ˆëê³ 
    - ì»¨í…Œì´ë„ˆ ë§ˆë‹¤ extraVolumeì„ kafka-volume(volumes)ë¡œ ì§€ì •í•´ë„ ì•ˆëë‹¤
    - volumes, volumesmountë¥¼ ì´ìš©í•´ë„ ì•ˆëë‹¤ 
    - ì•„ë˜ì˜ securityContextë¥¼ ì¨ì•¼ í•˜ë‚˜ ê³ ë¯¼..
```
# User and group of airflow user
uid: 50000
gid: 0

# Default security context for airflow (deprecated, use `securityContexts` instead)
securityContext: {}
#  runAsUser: 50000
#  fsGroup: 0
#  runAsGroup: 0

# Detailed default security context for airflow deployments
securityContexts:
  pod: {}
  containers: {}
```

- [?] ê·¼ë° ì§„ì§œ ì–¼ë–¨ê²°ì— í•´ê²°. volumesì™€ volumesmountì¤‘ volumemountë¥¼ ì£¼ì„ ì²˜ë¦¬ í›„ ë°°í¬í–ˆë”ë‹ˆ ë„ˆë¬´ ì˜ëë‹¤. ì´ìœ ê°€ ë­ì§€ ? 
 - [k] dagsë¥¼ scì™€ ì—°ê²°? -> ì•„ë‹˜ ìˆì—ˆìŒ
- [k] ì•„ë˜ ë‘ ê°œë¥¼ ìƒˆë¡­ê²Œ ì—°ê²°í•˜ê¸´ í•¨. 
 ```
 triggerer:
  persistence:
    enabled: true
    size: 5Gi
    storageClassName: cp-storageclass
redis:
  persistence:
    enabled: true
    size: 5Gi
    storageClassName: cp-storageclass
```

ğŸ¤” ê·¸ëŸ°ë° ë‚´ê°€ ë§‰ ì´ìƒí•˜ê²Œ dags.mountPathë¥¼ `/opt/airflow/kafka`ë¡œ í•´ë†“ì•˜ë”ë‹ˆ ëª¨ë“  dagíŒŒì¼ì´ ì—¬ê¸°ì— ë§ˆìš´íŠ¸ë˜ë”ë¼;;
### custom-values.yaml
```yaml
images:
  airflow:
    repository: seunghyejeong/airflow_v2
    tag: "1.0"
    digest: ~
    pullPolicy: IfNotPresent

# Load Examples
extraEnv: |
  - name: AIRFLOW__CORE__LOAD_EXAMPLES
    value: 'False'
  - name: AIRFLOW__CORE__DEFAULT_TIMEZONE
    value: 'Asia/Seoul'

#set executor
executor: "KubernetesExecutor"


volumes:
  - name: kafka-volume
    hostPath:
      path: /home/ubuntu/kafka
        #volumeMounts:
         #  - name: kafka-volume
         #    mountPath: /opt/airflow/kafka
         #    readOnly: false

# Webserver configure
webserver:
  defaultUser:
    enabled: true
    role: Admin
    username: admin
    email: admin@example.com
    firstName: admin
    lastName: admin
    password: admin
  service:
    type: NodePort
    ports:
      - name: airflow-ui
        port: 8080
        targetPort: 8080
        nodePort: 31151
  nodeSelector:
    node-role.kubernetes.io/control-plane: ""
  extraVolumeMounts:
    - name: airflow-dags
      mountPath: /opt/airflow/dags
    - name: kubeconfig-volume
      mountPath: /opt/airflow/.kube/kubeconfig
      readOnly: true
  extraVolumes:
    - name: airflow-dags
      persistentVolumeClaim:
        claimName: airflow-dags
    - name: kubeconfig-volume
      secret:
        secretName: kubeconfig-secret

workers:
  replicas: 1
  nodeSelector:
    node-role.kubernetes.io/control-plane: "
      "
webserverSecretKey: a717f95983a54fb8a822c40ba806cfc8

# bind w strogaeClass
dags:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
    accessMode: ReadWriteMany
    size: 5Gi
workers:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
    size: 5Gi
logs:
  persistence:
    enabled: true
    storageClassName: cp-storageclass
triggerer:
  persistence:
    enabled: true
    size: 5Gi
    storageClassName: cp-storageclass
redis:
  persistence:
    enabled: true
    size: 5Gi
    storageClassName: cp-storageclass

```

# KAFKA_STREAMING

ë°°í¬ëœ kafka, zookeeper ì¡°íšŒ 

```bash
kubectl get strimzipodsets -n kafka
NAME             PODS   READY PODS   CURRENT PODS   AGE
bami-kafka       1      1            1              29h
bami-zookeeper   1      1            1              29h
```

strimzië¡œ êµ¬ì„±ëœ network ì¡°íšŒ 
```bash
ubuntu@bami-node1:~$ kubectl get kafka -n kafka bami -o jsonpath={.status.listeners} | jq
[
  {
    "addresses": [
      {
        "host": "192.168.0.24",
        "port": 31207
      }
    ],
    "bootstrapServers": "192.168.0.24:31207",
    "name": "plain"
  },
  {
    "addresses": [
      {
        "host": "192.168.0.24",
        "port": 32507
      }
    ],
    "bootstrapServers": "192.168.0.24:32507",
    "name": "tls"
  }

```

- ë¸Œë¡œì»¤ ì •ë³´ ì¡°íšŒ
```
ubuntu@bami-node1:~/airflow$ kubectl exec -ti kafka-client -n kafka -- bash
[appuser@kafka-client ~]$ kafka-broker-api-versions --bootstrap-server=bami-kafka-plain-bootstrap.svc.kafka:9092
[2024-04-09 07:49:45,216] WARN Couldn't resolve server bami-kafka-plain-bootstrap.svc.kafka:9092 from bootstrap.servers as DNS resolution failed for bami-kafka-plain-bootstrap.svc.kafka (org.apache.kafka.clients.ClientUtils)
Exception in thread "main" org.apache.kafka.common.config.ConfigException: No resolvable bootstrap urls given in bootstrap.servers
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:101)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:60)
	at kafka.admin.BrokerApiVersionsCommand$AdminClient$.create(BrokerApiVersionsCommand.scala:284)
	at kafka.admin.BrokerApiVersionsCommand$AdminClient$.create(BrokerApiVersionsCommand.scala:267)
	at kafka.admin.BrokerApiVersionsCommand$AdminClient$.create(BrokerApiVersionsCommand.scala:265)
	at kafka.admin.BrokerApiVersionsCommand$.createAdminClient(BrokerApiVersionsCommand.scala:77)
	at kafka.admin.BrokerApiVersionsCommand$.execute(BrokerApiVersionsCommand.scala:59)
	at kafka.admin.BrokerApiVersionsCommand$.main(BrokerApiVersionsCommand.scala:54)
	at kafka.admin.BrokerApiVersionsCommand.main(BrokerApiVersionsCommand.scala)
[appuser@kafka-client ~]$ kafka-broker-api-versions --bootstrap-server=bami-kafka-plain-bootstrap.kafka.svc:9092
192.168.0.24:30774 (id: 0 rack: null) -> (
	Produce(0): 0 to 9 [usable: 9],
	Fetch(1): 0 to 15 [usable: 15],
	ListOffsets(2): 0 to 8 [usable: 8],
	Metadata(3): 0 to 12 [usable: 12],
	LeaderAndIsr(4): 0 to 7 [usable: 7],
	StopReplica(5): 0 to 4 [usable: 4],
	UpdateMetadata(6): 0 to 8 [usable: 8],
	ControlledShutdown(7): 0 to 3 [usable: 3],
	OffsetCommit(8): 0 to 8 [usable: 8],
	OffsetFetch(9): 0 to 8 [usable: 8],
	FindCoordinator(10): 0 to 4 [usable: 4],
	JoinGroup(11): 0 to 9 [usable: 9],
	Heartbeat(12): 0 to 4 [usable: 4],
	LeaveGroup(13): 0 to 5 [usable: 5],
	SyncGroup(14): 0 to 5 [usable: 5],
	DescribeGroups(15): 0 to 5 [usable: 5],
	ListGroups(16): 0 to 4 [usable: 4],
	SaslHandshake(17): 0 to 1 [usable: 1],
	ApiVersions(18): 0 to 3 [usable: 3],
	CreateTopics(19): 0 to 7 [usable: 7],
	DeleteTopics(20): 0 to 6 [usable: 6],
	DeleteRecords(21): 0 to 2 [usable: 2],
	InitProducerId(22): 0 to 4 [usable: 4],
	OffsetForLeaderEpoch(23): 0 to 4 [usable: 4],
	AddPartitionsToTxn(24): 0 to 4 [usable: 4],
	AddOffsetsToTxn(25): 0 to 3 [usable: 3],
	EndTxn(26): 0 to 3 [usable: 3],
	WriteTxnMarkers(27): 0 to 1 [usable: 1],
	TxnOffsetCommit(28): 0 to 3 [usable: 3],
	DescribeAcls(29): 0 to 3 [usable: 3],
	CreateAcls(30): 0 to 3 [usable: 3],
	DeleteAcls(31): 0 to 3 [usable: 3],
	DescribeConfigs(32): 0 to 4 [usable: 4],
	AlterConfigs(33): 0 to 2 [usable: 2],
	AlterReplicaLogDirs(34): 0 to 2 [usable: 2],
	DescribeLogDirs(35): 0 to 4 [usable: 4],
	SaslAuthenticate(36): 0 to 2 [usable: 2],
	CreatePartitions(37): 0 to 3 [usable: 3],
	CreateDelegationToken(38): 0 to 3 [usable: 3],
	RenewDelegationToken(39): 0 to 2 [usable: 2],
	ExpireDelegationToken(40): 0 to 2 [usable: 2],
	DescribeDelegationToken(41): 0 to 3 [usable: 3],
	DeleteGroups(42): 0 to 2 [usable: 2],
	ElectLeaders(43): 0 to 2 [usable: 2],
	IncrementalAlterConfigs(44): 0 to 1 [usable: 1],
	AlterPartitionReassignments(45): 0 [usable: 0],
	ListPartitionReassignments(46): 0 [usable: 0],
	OffsetDelete(47): 0 [usable: 0],
	DescribeClientQuotas(48): 0 to 1 [usable: 1],
	AlterClientQuotas(49): 0 to 1 [usable: 1],
	DescribeUserScramCredentials(50): 0 [usable: 0],
	AlterUserScramCredentials(51): 0 [usable: 0],
	DescribeQuorum(55): UNSUPPORTED,
	AlterPartition(56): 0 to 3 [usable: 3],
	UpdateFeatures(57): 0 to 1 [usable: 1],
	Envelope(58): 0 [usable: 0],
	DescribeCluster(60): 0 [usable: 0],
	DescribeProducers(61): 0 [usable: 0],
	UnregisterBroker(64): UNSUPPORTED,
	DescribeTransactions(65): 0 [usable: 0],
	ListTransactions(66): 0 [usable: 0],
	AllocateProducerIds(67): 0 [usable: 0],
	ConsumerGroupHeartbeat(68): UNSUPPORTED
```

- [b] ref
> [messagingë°˜ë³µí•˜ê¸° ](https://velog.io/@yoojh5099/Kafka-Strimzi-Operator)
> [strimzië¡œ ë°°í¬ ë° ì‹¤í–‰í•˜ê¸°](https://velog.io/@yoojh5099/Kafka-Strimzi-Operator)

- [?] KEDA ì‚¬ìš©?

```
kafka-console-producer --topic kafka-topic --bootstrap-server 192.168.0.24:31207
```